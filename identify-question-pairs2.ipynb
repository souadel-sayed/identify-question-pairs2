{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6277,"databundleVersionId":323734,"sourceType":"competition"},{"sourceId":8006,"sourceType":"datasetVersion","datasetId":5314}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install contractions\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport gc\nimport re\nimport numpy as np\nimport pandas as pd\nimport unicodedata\nimport contractions\nfrom collections import defaultdict\nfrom sklearn.preprocessing import StandardScaler\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Dense, Input, Embedding, Dropout, LSTM\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nimport tensorflow.keras.backend as K","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-29T21:26:38.227044Z","iopub.execute_input":"2024-02-29T21:26:38.227759Z","iopub.status.idle":"2024-02-29T21:26:53.070128Z","shell.execute_reply.started":"2024-02-29T21:26:38.227718Z","shell.execute_reply":"2024-02-29T21:26:53.069294Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: contractions in /opt/conda/lib/python3.10/site-packages (0.1.73)\nRequirement already satisfied: textsearch>=0.0.21 in /opt/conda/lib/python3.10/site-packages (from contractions) (0.0.24)\nRequirement already satisfied: anyascii in /opt/conda/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\nRequirement already satisfied: pyahocorasick in /opt/conda/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = '/kaggle/input/quora-question-pairs/train.csv.zip'\ntest_path = '/kaggle/input/quora-question-pairs/test.csv'\nembeddings_path = '/kaggle/input/glove-840b-300d/glove.840B.300d.txt'","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:27:14.753269Z","iopub.execute_input":"2024-02-29T21:27:14.754364Z","iopub.status.idle":"2024-02-29T21:27:14.758637Z","shell.execute_reply.started":"2024-02-29T21:27:14.754326Z","shell.execute_reply":"2024-02-29T21:27:14.757659Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"embeddings_dict = {}\nembedding_size = 300\n\nwith open(embeddings_path, encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = ''.join(values[:-embedding_size])   \n        embeddings_dict[word] = np.asarray(values[-embedding_size:], dtype='float32')\n\nprint(f'{len(embeddings_dict)} embedding vectors are read successfully')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:27:15.810009Z","iopub.execute_input":"2024-02-29T21:27:15.810842Z","iopub.status.idle":"2024-02-29T21:30:09.960029Z","shell.execute_reply.started":"2024-02-29T21:27:15.810805Z","shell.execute_reply":"2024-02-29T21:30:09.959016Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2195892 embedding vectors are read successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv(train_path, encoding='utf-8')\ntrain_df = train_df.fillna('Empty')\ntrain_labels = train_df.is_duplicate.values","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:23:26.081136Z","iopub.execute_input":"2024-02-29T22:23:26.081486Z","iopub.status.idle":"2024-02-29T22:23:27.622316Z","shell.execute_reply.started":"2024-02-29T22:23:26.081458Z","shell.execute_reply":"2024-02-29T22:23:27.621463Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(test_path, encoding='utf-8')\ntest_df = test_df.fillna('Empty')\ntest_ids = test_df.test_id.values","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:30:11.595617Z","iopub.execute_input":"2024-02-29T21:30:11.595920Z","iopub.status.idle":"2024-02-29T21:30:18.141226Z","shell.execute_reply.started":"2024-02-29T21:30:11.595894Z","shell.execute_reply":"2024-02-29T21:30:18.140443Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#  Pre prosessing AND Feature Extraction  ","metadata":{}},{"cell_type":"code","source":"def text_preprocess(text, remove_stopwords=False, stem_words=False):\n    text = text.lower().split()\n\n    pattern = re.compile('<.*?>')\n    text = pattern.sub(r'', str(text))\n    \n    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    text = pattern.sub(r'', str(text))\n    \n    text = text.translate(text.maketrans(\"\\n\\t\\r\", \"   \"))\n    \n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore') \\\n                                              .decode('utf-8', 'ignore')\n    text = text.strip()\n    \n    text = contractions.fix(text)\n    \n    special_char_pattern = re.compile(r'([{.(-)!}])')\n    text = special_char_pattern.sub(\" \\\\1 \", text)    \n    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text).strip()\n    \n    if remove_stopwords:\n        stop_words = set(stopwords.words(\"english\"))\n        text = [w for w in text if not w in stop_words]\n    \n    text = \" \".join(text)\n    \n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    return(text)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:30:18.143568Z","iopub.execute_input":"2024-02-29T21:30:18.143878Z","iopub.status.idle":"2024-02-29T21:30:18.153931Z","shell.execute_reply.started":"2024-02-29T21:30:18.143850Z","shell.execute_reply":"2024-02-29T21:30:18.152876Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_preprocessed_q1 = [] \ntrain_preprocessed_q2 = []\n\nfor text in train_df.question1.values:\n    train_preprocessed_q1.append(text_preprocess(text, remove_stopwords=False, stem_words=False))\n    \nfor text in train_df.question2.values:\n    train_preprocessed_q2.append(text_preprocess(text, remove_stopwords=False, stem_words=False))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:30:18.155202Z","iopub.execute_input":"2024-02-29T21:30:18.155541Z","iopub.status.idle":"2024-02-29T21:30:57.307344Z","shell.execute_reply.started":"2024-02-29T21:30:18.155503Z","shell.execute_reply":"2024-02-29T21:30:57.306317Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_preprocessed_q1 = []\ntest_preprocessed_q2 = []\n\nfor text in test_df.question1.values:\n    test_preprocessed_q1.append(text_preprocess(text, remove_stopwords=False, stem_words=False))\n    \nfor text in test_df.question2.values:\n    test_preprocessed_q2.append(text_preprocess(text, remove_stopwords=False, stem_words=False))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:30:57.308460Z","iopub.execute_input":"2024-02-29T21:30:57.308745Z","iopub.status.idle":"2024-02-29T21:34:48.357710Z","shell.execute_reply.started":"2024-02-29T21:30:57.308719Z","shell.execute_reply":"2024-02-29T21:34:48.356609Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"max_tokens = 200000\ntokenizer = Tokenizer(num_words=max_tokens)\ntokenizer.fit_on_texts(train_preprocessed_q1 + train_preprocessed_q2 + test_preprocessed_q1 + test_preprocessed_q2)\n\ntrain_sequences_1 = tokenizer.texts_to_sequences(train_preprocessed_q1)\ntrain_sequences_2 = tokenizer.texts_to_sequences(train_preprocessed_q2)\ntest_sequences_1 = tokenizer.texts_to_sequences(test_preprocessed_q1)\ntest_sequences_2 = tokenizer.texts_to_sequences(test_preprocessed_q2)\nword_index = tokenizer.word_index\nprint('{} unique tokens are found'.format(len(word_index)))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:34:48.358854Z","iopub.execute_input":"2024-02-29T21:34:48.359153Z","iopub.status.idle":"2024-02-29T21:41:23.578543Z","shell.execute_reply.started":"2024-02-29T21:34:48.359127Z","shell.execute_reply":"2024-02-29T21:41:23.574595Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"36 unique tokens are found\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_preprocessed_q1\ndel train_preprocessed_q2\ndel test_preprocessed_q1\ndel test_preprocessed_q2\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:41:23.580090Z","iopub.execute_input":"2024-02-29T21:41:23.580512Z","iopub.status.idle":"2024-02-29T21:41:25.719323Z","shell.execute_reply.started":"2024-02-29T21:41:23.580466Z","shell.execute_reply":"2024-02-29T21:41:25.718116Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"max_seq_len = 60\ntrain_embeddings_q1 = pad_sequences(train_sequences_1, maxlen=max_seq_len)\ntrain_embeddings_q2 = pad_sequences(train_sequences_2, maxlen=max_seq_len)\nprint('Shape of train embeddings: ', train_embeddings_q1.shape)\nprint('Shape of train labels: ', train_labels.shape)\n\ntest_embeddings_q1 = pad_sequences(test_sequences_1, maxlen=max_seq_len)\ntest_embeddings_q2 = pad_sequences(test_sequences_2, maxlen=max_seq_len)\nprint('Shape of test embeddings: ', test_embeddings_q2.shape)\nprint('Shape of test ids: ', test_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:41:25.720750Z","iopub.execute_input":"2024-02-29T21:41:25.721126Z","iopub.status.idle":"2024-02-29T21:42:03.921901Z","shell.execute_reply.started":"2024-02-29T21:41:25.721091Z","shell.execute_reply":"2024-02-29T21:42:03.920716Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Shape of train embeddings:  (404290, 60)\nShape of train labels:  (404290,)\nShape of test embeddings:  (2345796, 60)\nShape of test ids:  (2345796,)\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_sequences_1\ndel train_sequences_2\ndel test_sequences_1\ndel test_sequences_2\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:42:03.925825Z","iopub.execute_input":"2024-02-29T21:42:03.926158Z","iopub.status.idle":"2024-02-29T21:42:05.442974Z","shell.execute_reply.started":"2024-02-29T21:42:03.926128Z","shell.execute_reply":"2024-02-29T21:42:05.441861Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# graph features\nquestions = pd.concat([train_df[['question1', 'question2']],\n                       test_df[['question1', 'question2']]],\n                       axis=0).reset_index(drop='index')\n\nq_adj_list = defaultdict(set)\nfor i in range(questions.shape[0]):\n    q_adj_list[questions.question1[i]].add(questions.question2[i])\n    q_adj_list[questions.question2[i]].add(questions.question1[i])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:42:05.444172Z","iopub.execute_input":"2024-02-29T21:42:05.444503Z","iopub.status.idle":"2024-02-29T21:44:59.887166Z","shell.execute_reply.started":"2024-02-29T21:42:05.444476Z","shell.execute_reply":"2024-02-29T21:44:59.886326Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def q1_freq(row):\n    \"\"\"Number of adjacent nodes.\"\"\"\n    return (len(q_adj_list[row['question1']]))\n    \ndef q2_freq(row):\n    \"\"\"Number of adjacent nodes.\"\"\"\n    return (len(q_adj_list[row['question2']]))\n    \ndef q1_q2_intersect(row):\n    \"\"\"Number of adjacent nodes common to q1 and q2.\"\"\"\n    return (len(set(q_adj_list[row['question1']]).intersection(set(q_adj_list[row['question2']]))))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:44:59.888498Z","iopub.execute_input":"2024-02-29T21:44:59.888888Z","iopub.status.idle":"2024-02-29T21:44:59.895687Z","shell.execute_reply.started":"2024-02-29T21:44:59.888852Z","shell.execute_reply":"2024-02-29T21:44:59.894768Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(q_adj_list[\"Which one dissolve in water quikly sugar, salt... \"])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:44:59.897091Z","iopub.execute_input":"2024-02-29T21:44:59.897403Z","iopub.status.idle":"2024-02-29T21:44:59.912190Z","shell.execute_reply.started":"2024-02-29T21:44:59.897376Z","shell.execute_reply":"2024-02-29T21:44:59.911384Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"train_df['q1_q2_intersect'] = train_df.apply(q1_q2_intersect, axis=1)\ntrain_df['q1_freq'] = train_df.apply(q1_freq, axis=1)\ntrain_df['q2_freq'] = train_df.apply(q2_freq, axis=1)\n\ntest_df['q1_q2_intersect'] = test_df.apply(q1_q2_intersect, axis=1)\ntest_df['q1_freq'] = test_df.apply(q1_freq, axis=1)\ntest_df['q2_freq'] = test_df.apply(q2_freq, axis=1)\n\ntrain_graph_feat = train_df[['q1_q2_intersect', 'q1_freq', 'q2_freq']].copy()\ntest_graph_feat = test_df[['q1_q2_intersect', 'q1_freq', 'q2_freq']].copy()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:31:14.831019Z","iopub.execute_input":"2024-02-29T22:31:14.831389Z","iopub.status.idle":"2024-02-29T22:31:30.779269Z","shell.execute_reply.started":"2024-02-29T22:31:14.831358Z","shell.execute_reply":"2024-02-29T22:31:30.778457Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# del train_df\n# del test_df\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:46:44.264937Z","iopub.execute_input":"2024-02-29T21:46:44.265248Z","iopub.status.idle":"2024-02-29T21:46:46.205126Z","shell.execute_reply.started":"2024-02-29T21:46:44.265214Z","shell.execute_reply":"2024-02-29T21:46:46.204197Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# # 1) length of the bothe question\n# train_df['q1_len'] = train_df['question1'].str.len()\n# train_df['q2_len'] = train_df['question2'].str.len()\n\n\n# 2) Add number of words columns \n\ntrain_df['q1_words'] = train_df['question1'].apply(lambda row: len(row.split(\" \")))\ntrain_df['q2_words'] = train_df['question2'].apply(lambda row: len(row.split(\" \")))\n\n\n# 3) Number of same words in the pair of questions\ndef common_words(row):\n    w1 = set(map(lambda word : word.lower().strip(),row['question1'].split(\" \")))\n    w2 = set(map(lambda word : word.lower().strip(),row['question2'].split(\" \")))\n    return len(w1 & w2)\n\ntrain_df['Common_words'] = train_df.apply(common_words,axis=1)\ntrain_df.head()\n\n# 4)total Number of  words in the all of 2 questions\n\ndef word_total(row):\n    q1 = set(map(lambda word : word.lower().strip(),row['question1'].split(\" \")))\n    q2 = set(map(lambda word : word.lower().strip(),row['question2'].split(\" \")))\n\n    return len(q1)+len(q2)\ntrain_df['total_words'] = train_df.apply(word_total,axis=1)\n\n\n# for word share\ndef word_share(row):\n    return round(row['Common_words']/row['total_words'],2)\ntrain_df['word_share'] = train_df.apply(word_share,axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:30:18.355352Z","iopub.execute_input":"2024-02-29T22:30:18.356111Z","iopub.status.idle":"2024-02-29T22:30:47.092095Z","shell.execute_reply.started":"2024-02-29T22:30:18.356075Z","shell.execute_reply":"2024-02-29T22:30:47.090958Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# ML model","metadata":{}},{"cell_type":"code","source":"x = train_df[[ 'q1_q2_intersect','q1_freq','q2_freq', 'q1_words','q2_words',  'word_share']]","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:31:35.766078Z","iopub.execute_input":"2024-02-29T22:31:35.766442Z","iopub.status.idle":"2024-02-29T22:31:35.776736Z","shell.execute_reply.started":"2024-02-29T22:31:35.766413Z","shell.execute_reply":"2024-02-29T22:31:35.775567Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"y=train_df.is_duplicate","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:31:37.214130Z","iopub.execute_input":"2024-02-29T22:31:37.214980Z","iopub.status.idle":"2024-02-29T22:31:37.219452Z","shell.execute_reply.started":"2024-02-29T22:31:37.214929Z","shell.execute_reply":"2024-02-29T22:31:37.218459Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,\n                                                    y,\n                                                    test_size=0.33,\n                                                    random_state=41\n                                                    )","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:31:37.569963Z","iopub.execute_input":"2024-02-29T22:31:37.570852Z","iopub.status.idle":"2024-02-29T22:31:37.629820Z","shell.execute_reply.started":"2024-02-29T22:31:37.570815Z","shell.execute_reply":"2024-02-29T22:31:37.628737Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=5)\nrf.fit(x_train,y_train)\n\ny_pred = rf.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:31:37.959945Z","iopub.execute_input":"2024-02-29T22:31:37.960598Z","iopub.status.idle":"2024-02-29T22:32:34.768165Z","shell.execute_reply.started":"2024-02-29T22:31:37.960563Z","shell.execute_reply":"2024-02-29T22:32:34.767056Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\n# Make predictions on the training data\ny_train_pred = rf.predict(x_train)\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_train, y_train_pred)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:32:34.770234Z","iopub.execute_input":"2024-02-29T22:32:34.771052Z","iopub.status.idle":"2024-02-29T22:32:42.955000Z","shell.execute_reply.started":"2024-02-29T22:32:34.771010Z","shell.execute_reply":"2024-02-29T22:32:42.954050Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"0.8642505371501141"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:32:42.956181Z","iopub.execute_input":"2024-02-29T22:32:42.956485Z","iopub.status.idle":"2024-02-29T22:32:43.159866Z","shell.execute_reply.started":"2024-02-29T22:32:42.956459Z","shell.execute_reply":"2024-02-29T22:32:43.158896Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.93      0.86      0.89     90575\n           1       0.74      0.85      0.79     42841\n\n    accuracy                           0.86    133416\n   macro avg       0.83      0.86      0.84    133416\nweighted avg       0.87      0.86      0.86    133416\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# lstm","metadata":{}},{"cell_type":"code","source":"num_words = min(max_tokens, len(word_index))+1\nembedding_matrix = np.zeros((num_words, embedding_size))\n\nfor word, i in word_index.items():\n    embedding_vector = embeddings_dict.get(word)\n    \n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:47:16.452839Z","iopub.execute_input":"2024-02-29T21:47:16.453630Z","iopub.status.idle":"2024-02-29T21:47:16.459227Z","shell.execute_reply.started":"2024-02-29T21:47:16.453595Z","shell.execute_reply":"2024-02-29T21:47:16.458288Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"del embeddings_dict\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:47:16.843885Z","iopub.execute_input":"2024-02-29T21:47:16.844846Z","iopub.status.idle":"2024-02-29T21:47:19.564336Z","shell.execute_reply.started":"2024-02-29T21:47:16.844813Z","shell.execute_reply":"2024-02-29T21:47:19.563321Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"488"},"metadata":{}}]},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(np.vstack((train_graph_feat, test_graph_feat)))\ntrain_graph_feat = scaler.transform(train_graph_feat)\ntest_graph_feat = scaler.transform(test_graph_feat)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:47:19.566523Z","iopub.execute_input":"2024-02-29T21:47:19.567224Z","iopub.status.idle":"2024-02-29T21:47:19.690653Z","shell.execute_reply.started":"2024-02-29T21:47:19.567186Z","shell.execute_reply":"2024-02-29T21:47:19.689559Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"val_ratio = 0.1\nperm = np.random.permutation(len(train_embeddings_q1))\nidx_train = perm[:int(len(train_embeddings_q1)*(1-val_ratio))]\nidx_val = perm[int(len(train_embeddings_q1)*(1-val_ratio)):]\n\ndata_1_train = np.vstack((train_embeddings_q1[idx_train], train_embeddings_q2[idx_train]))\ndata_2_train = np.vstack((train_embeddings_q2[idx_train], train_embeddings_q1[idx_train]))\ngraph_train = np.vstack((train_graph_feat[idx_train], train_graph_feat[idx_train]))\nlabels_train = np.concatenate((train_labels[idx_train], train_labels[idx_train]))\n\ndata_1_val = np.vstack((train_embeddings_q1[idx_val], train_embeddings_q2[idx_val]))\ndata_2_val = np.vstack((train_embeddings_q2[idx_val], train_embeddings_q1[idx_val]))\ngraph_val = np.vstack((train_graph_feat[idx_val], train_graph_feat[idx_val]))\nlabels_val = np.concatenate((train_labels[idx_val], train_labels[idx_val]))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:47:20.110131Z","iopub.execute_input":"2024-02-29T21:47:20.110632Z","iopub.status.idle":"2024-02-29T21:47:20.455667Z","shell.execute_reply.started":"2024-02-29T21:47:20.110594Z","shell.execute_reply":"2024-02-29T21:47:20.454569Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"weight_val = np.ones(len(labels_val))\nweight_val *= 0.471544715\nweight_val[labels_val == 0] = 1.309033281","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:47:20.919800Z","iopub.execute_input":"2024-02-29T21:47:20.920173Z","iopub.status.idle":"2024-02-29T21:47:20.926553Z","shell.execute_reply.started":"2024-02-29T21:47:20.920142Z","shell.execute_reply":"2024-02-29T21:47:20.925562Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"emb_layer = Embedding(\n    input_dim=num_words,\n    output_dim=embedding_size,\n    weights=[embedding_matrix],\n    input_length=max_seq_len,\n    trainable=False\n)    \n\nlstm_layer = LSTM(200, dropout=0.15, recurrent_dropout=0.15)\n\nseq1 = Input(shape=(max_seq_len,), dtype='int32')\nseq2 = Input(shape=(max_seq_len,), dtype='int32')\n\nemb1 = emb_layer(seq1)\nemb2 = emb_layer(seq2)\n\nlstm_a = lstm_layer(emb1)\nlstm_b = lstm_layer(emb2)\n\ngraph_inp = Input(shape=(train_graph_feat.shape[1],))\ngraph_dense = Dense(75, activation='relu')(graph_inp)\n\nmerged = concatenate([lstm_a, lstm_b, graph_dense])\nmerged = BatchNormalization()(merged)\nmerged = Dropout(0.3)(merged)\n\nmerged = Dense(150, activation='relu')(merged)\nmerged = BatchNormalization()(merged)\nmerged = Dropout(0.3)(merged)\n\npreds = Dense(1, activation='sigmoid')(merged)\n\nmodel = Model(inputs=[seq1, seq2, graph_inp], outputs=preds)\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:47:22.110959Z","iopub.execute_input":"2024-02-29T21:47:22.111484Z","iopub.status.idle":"2024-02-29T21:47:24.865260Z","shell.execute_reply.started":"2024-02-29T21:47:22.111451Z","shell.execute_reply":"2024-02-29T21:47:24.864232Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5)\nbest_model_path = 'lstm.h5' \nclass_weight = {0: 1.309033281, 1: 0.471544715}\n\nmodel_checkpoint = ModelCheckpoint(best_model_path, save_best_only=True, save_weights_only=True)\n\nhist = model.fit([data_1_train, data_2_train, graph_train], labels_train, \\\n        validation_data=([data_1_val, data_2_val, graph_val], labels_val, weight_val), \\\n        epochs=15, batch_size=2048, shuffle=True, \\\n        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:47:24.866949Z","iopub.execute_input":"2024-02-29T21:47:24.867254Z","iopub.status.idle":"2024-02-29T22:20:28.397745Z","shell.execute_reply.started":"2024-02-29T21:47:24.867227Z","shell.execute_reply":"2024-02-29T22:20:28.396914Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/15\n356/356 [==============================] - 167s 440ms/step - loss: 0.2951 - acc: 0.8155 - val_loss: 0.2979 - val_acc: 0.7742\nEpoch 2/15\n356/356 [==============================] - 130s 367ms/step - loss: 0.2543 - acc: 0.8284 - val_loss: 0.2484 - val_acc: 0.8271\nEpoch 3/15\n356/356 [==============================] - 130s 366ms/step - loss: 0.2447 - acc: 0.8320 - val_loss: 0.2420 - val_acc: 0.8405\nEpoch 4/15\n356/356 [==============================] - 130s 365ms/step - loss: 0.2372 - acc: 0.8354 - val_loss: 0.2315 - val_acc: 0.8387\nEpoch 5/15\n356/356 [==============================] - 130s 364ms/step - loss: 0.2305 - acc: 0.8396 - val_loss: 0.2287 - val_acc: 0.8487\nEpoch 6/15\n356/356 [==============================] - 130s 365ms/step - loss: 0.2252 - acc: 0.8432 - val_loss: 0.2227 - val_acc: 0.8504\nEpoch 7/15\n356/356 [==============================] - 129s 364ms/step - loss: 0.2204 - acc: 0.8461 - val_loss: 0.2203 - val_acc: 0.8540\nEpoch 8/15\n356/356 [==============================] - 129s 363ms/step - loss: 0.2164 - acc: 0.8489 - val_loss: 0.2176 - val_acc: 0.8551\nEpoch 9/15\n356/356 [==============================] - 129s 363ms/step - loss: 0.2121 - acc: 0.8519 - val_loss: 0.2243 - val_acc: 0.8662\nEpoch 10/15\n356/356 [==============================] - 129s 363ms/step - loss: 0.2085 - acc: 0.8545 - val_loss: 0.2142 - val_acc: 0.8530\nEpoch 11/15\n356/356 [==============================] - 130s 365ms/step - loss: 0.2048 - acc: 0.8571 - val_loss: 0.2146 - val_acc: 0.8662\nEpoch 12/15\n356/356 [==============================] - 130s 365ms/step - loss: 0.2012 - acc: 0.8599 - val_loss: 0.2125 - val_acc: 0.8651\nEpoch 13/15\n356/356 [==============================] - 130s 364ms/step - loss: 0.1978 - acc: 0.8623 - val_loss: 0.2110 - val_acc: 0.8665\nEpoch 14/15\n356/356 [==============================] - 129s 362ms/step - loss: 0.1945 - acc: 0.8647 - val_loss: 0.2136 - val_acc: 0.8701\nEpoch 15/15\n356/356 [==============================] - 129s 363ms/step - loss: 0.1916 - acc: 0.8670 - val_loss: 0.2217 - val_acc: 0.8736\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights(best_model_path)\nbest_val_score = min(hist.history['val_loss'])\nbest_val_acc = max(hist.history['val_acc'])\nprint(best_val_score, best_val_acc)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:20:28.399080Z","iopub.execute_input":"2024-02-29T22:20:28.399366Z","iopub.status.idle":"2024-02-29T22:20:28.435879Z","shell.execute_reply.started":"2024-02-29T22:20:28.399340Z","shell.execute_reply":"2024-02-29T22:20:28.434990Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"0.21095313131809235 0.8736426830291748\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = model.predict([test_embeddings_q1, test_embeddings_q2, test_graph_feat], batch_size=2048, verbose=1)\npredictions += model.predict([test_embeddings_q2, test_embeddings_q1, test_graph_feat], batch_size=2048, verbose=1)\npredictions /= 2","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:20:28.438178Z","iopub.execute_input":"2024-02-29T22:20:28.438617Z","iopub.status.idle":"2024-02-29T22:23:26.079842Z","shell.execute_reply.started":"2024-02-29T22:20:28.438583Z","shell.execute_reply":"2024-02-29T22:23:26.078600Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"1146/1146 [==============================] - 88s 76ms/step\n1146/1146 [==============================] - 87s 76ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# DL model","metadata":{}},{"cell_type":"code","source":"dtrain=np.hstack((train_embeddings_q1,train_embeddings_q2))\ndtrain=pad_sequences(dtrain,maxlen=116)\n\nprint(\"dtrain\" ,dtrain.shape)\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(dtrain,\n                                                    train_labels,\n                                                    test_size=0.33,\n                                                    random_state=41\n                                                    )\n\nT=dtrain.shape[1]\nword2idx=tokenizer.word_index\nV=len(word2idx)\nD=20","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:24:51.615385Z","iopub.execute_input":"2024-02-29T22:24:51.616167Z","iopub.status.idle":"2024-02-29T22:24:52.950379Z","shell.execute_reply.started":"2024-02-29T22:24:51.616130Z","shell.execute_reply":"2024-02-29T22:24:52.949329Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"dtrain (404290, 116)\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Conv1D, MaxPooling1D, Dropout, Flatten, Dense, Activation, BatchNormalization, Input, Embedding, GlobalMaxPooling1D\nfrom keras.callbacks import EarlyStopping\nfrom keras import regularizers\n\n# Define regularization and early stopping parameters\nl2_value = 0.02  # L2 regularization strength\ndropout_rate = 0.5  # Dropout rate\npatience = 3  # Number of epochs with no improvement before stopping\n\n# Model architecture\ni = Input(shape=(T,))\nx = Embedding(V+1, D)(i)\nx = Conv1D(32, 3, activation='relu', kernel_regularizer=regularizers.l2(l2_value))(x)\nx = MaxPooling1D(4)(x)\nx = Dropout(dropout_rate)(x)\nx = Conv1D(64, 3, activation='relu', kernel_regularizer=regularizers.l2(l2_value))(x)\nx = MaxPooling1D(4)(x)\nx = Dropout(dropout_rate)(x)\nx = Conv1D(128, 3, activation='relu', kernel_regularizer=regularizers.l2(l2_value))(x)\nx = GlobalMaxPooling1D()(x)\nx = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(l2_value))(x)\n\nmodel = Model(i, x)\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n\n# Train the model with early stopping\nmodel.fit(x_train, y_train,\n          epochs=100,\n          validation_data=(x_test, y_test),\n          callbacks=[early_stopping])\n\n# Print model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T22:25:30.312451Z","iopub.execute_input":"2024-02-29T22:25:30.313416Z","iopub.status.idle":"2024-02-29T22:29:42.059735Z","shell.execute_reply.started":"2024-02-29T22:25:30.313359Z","shell.execute_reply":"2024-02-29T22:29:42.058744Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/100\n8465/8465 [==============================] - 55s 6ms/step - loss: 0.6737 - accuracy: 0.6311 - val_loss: 0.6589 - val_accuracy: 0.6303\nEpoch 2/100\n8465/8465 [==============================] - 49s 6ms/step - loss: 0.6585 - accuracy: 0.6311 - val_loss: 0.6588 - val_accuracy: 0.6303\nEpoch 3/100\n8465/8465 [==============================] - 49s 6ms/step - loss: 0.6584 - accuracy: 0.6311 - val_loss: 0.6588 - val_accuracy: 0.6303\nEpoch 4/100\n8465/8465 [==============================] - 50s 6ms/step - loss: 0.6584 - accuracy: 0.6311 - val_loss: 0.6588 - val_accuracy: 0.6303\nEpoch 5/100\n8465/8465 [==============================] - 49s 6ms/step - loss: 0.6584 - accuracy: 0.6311 - val_loss: 0.6588 - val_accuracy: 0.6303\nEpoch 5: early stopping\nModel: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 116)]             0         \n                                                                 \n embedding_1 (Embedding)     (None, 116, 20)           740       \n                                                                 \n conv1d (Conv1D)             (None, 114, 32)           1952      \n                                                                 \n max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n )                                                               \n                                                                 \n dropout_2 (Dropout)         (None, 28, 32)            0         \n                                                                 \n conv1d_1 (Conv1D)           (None, 26, 64)            6208      \n                                                                 \n max_pooling1d_1 (MaxPooling  (None, 6, 64)            0         \n 1D)                                                             \n                                                                 \n dropout_3 (Dropout)         (None, 6, 64)             0         \n                                                                 \n conv1d_2 (Conv1D)           (None, 4, 128)            24704     \n                                                                 \n global_max_pooling1d (Globa  (None, 128)              0         \n lMaxPooling1D)                                                  \n                                                                 \n dense_3 (Dense)             (None, 1)                 129       \n                                                                 \n=================================================================\nTotal params: 33,733\nTrainable params: 33,733\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}